{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KL _divergence and BT_Domain_extraction",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhardwaj1230/Natural-Language-Processing/blob/master/KL_divergence_and_Domain_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MvKw44TRfox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zOIBt_9RbxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Domain of all data :\n",
        "\n",
        "def read_data(loc):\n",
        "    objects = []\n",
        "    with (open(loc, \"rb\")) as openfile: \n",
        "        while True:\n",
        "            try:\n",
        "                objects.append(pickle.load(openfile))\n",
        "            except EOFError:\n",
        "                break\n",
        "    return objects\n",
        "\n",
        "address_not_flagged = read_data(\"/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/complete_not_flagged/not_flagged_loc.en-fr\")\n",
        "address_flagged = read_data(\"/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/complete_flagged/all_loc.en-fr\")\n",
        "\n",
        "address_not_flagged = [item for ad in address_not_flagged for item in ad]\n",
        "address_flagged = [item for ad in address_flagged for item in ad]\n",
        "\n",
        "address = address_not_flagged + address_flagged\n",
        "\n",
        "address = set(address)\n",
        "locations=[]\n",
        "for item in address:\n",
        "    locations.append(item[:-2])\n",
        "\n",
        "locations = list(set(locations))\n",
        "\n",
        "new_location = []\n",
        "for loc in locations:\n",
        "    new_location.append(loc.replace('/space/project/portage/corpora/BtB/MegaCorpus_2019-02-14/', '/gpfs/fs2c/nrc/ict/nrc_collab_aitq/'))\n",
        "\n",
        "\n",
        "def get_data(loc):\n",
        "\n",
        "    cnt_e = 0\n",
        "    counts = {}\n",
        "\n",
        "    for en_fr in tqdm(loc):\n",
        "        if os.path.exists(en_fr+str('fr')) and os.path.exists(en_fr+str('en')):\n",
        "\n",
        "            with open(en_fr+str('fr')) as f, open(en_fr+str('en')) as e:\n",
        "                domain_folder = en_fr.replace('/gpfs/fs2c/nrc/ict/nrc_collab_aitq/corpus_renamed/','')\n",
        "                for fr, en in zip(f, e):\n",
        "                    cnt_e +=1\n",
        "                if domain_folder.split('/')[1] in counts:\n",
        "                    counts[domain_folder.split('/')[1]] += cnt_e\n",
        "                else:\n",
        "                    counts[domain_folder.split('/')[1]] = cnt_e\n",
        "                cnt_e = 0\n",
        "    \n",
        "    with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/BT_Doamin_distribution.en-fr','wb') as w:\n",
        "        pickle.dump(counts, w)\n",
        "\n",
        "get_data(new_location)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zAYLnqiHu5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get domain from downloaded 14M data for NMT :\n",
        "\n",
        "\n",
        "with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/train/flag_not_flagged/train.en-fr.en','r') as r:\n",
        "\tflag_en = [item for item in r.readlines()]\n",
        "\n",
        "with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/train/flag_not_flagged/train.en-fr.fr','r') as r:\n",
        "\tflag_fr = [item for item in r.readlines()]\n",
        "\n",
        "def join(a,b):\n",
        "    en_fr = []\n",
        "    for x,y in tqdm(zip(a,b)):\n",
        "        x = str(x)\n",
        "        y = str(y)\n",
        "        en_fr.append(' @$$$$@ '.join([x, y]))\n",
        "    return en_fr\n",
        "\n",
        "flagged = join(flag_fr , flag_en)    \n",
        "flagged = set(flagged)\n",
        "flag_en = 0\n",
        "flag_fr = 0 \n",
        "\n",
        "def get_data(loc):\n",
        "    \n",
        "    data_info = []\n",
        "    \n",
        "    for en_fr in tqdm(loc):\n",
        "        if os.path.exists(en_fr+str('fr')) and os.path.exists(en_fr+str('en')):\n",
        "\n",
        "            with open(en_fr+str('fr')) as f, open(en_fr+str('en')) as e:\n",
        "                for idx, (line_f, line_e) in enumerate(zip(f,e)):\n",
        "\n",
        "                    if line_f+' @$$$$@ '+line_e in flagged:\n",
        "                        #print((line_f.strip('\\n'),line_e.strip('\\n'),en_fr,idx))\n",
        "                        data_info.append((line_f.strip('\\n'),line_e.strip('\\n'),en_fr,idx))\n",
        "\n",
        "    with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/data_info.en-fr','wb') as w:\n",
        "        pickle.dump(data_info, w)\n",
        "\n",
        "    \n",
        "get_data(new_location)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX8b4LE2H5TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/domain_distribution/14M_BT_domain_info.en-fr', 'rb') as handle:\n",
        "    bt_14 = pickle.load(handle)\n",
        "\n",
        "data_14M =[]\n",
        "for f,e,loc,idx in bt_14: \n",
        "    loc_clean = loc.replace('/gpfs/fs2c/nrc/ict/nrc_collab_aitq/corpus_renamed/', '')\n",
        "    data_14M.append((f,e,loc_clean.split('/')[0],loc_clean.split('/')[1],idx))\n",
        "\n",
        "counts_14M = dict()\n",
        "for f, e, folder, domain, idx in data_14M:\n",
        "    if domain in counts_14M:\n",
        "        #print('yes')\n",
        "        counts_14M[domain] += 1\n",
        "    else:\n",
        "        counts_14M[domain] = 1\n",
        "\n",
        "\n",
        "with open('/fs/hestia_Hnrc/ict/bha101/nrc_collab_aitq/bt/domain_distribution/BT_Domain_distribution.en-fr', 'rb') as handle:\n",
        "    counts = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPP1fLuuH5Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# missing Domains :\n",
        "set(counts.keys()) - set(counts_14M.keys())\n",
        "\n",
        "#Common domains :\n",
        "counts.keys() & counts_14M.keys()\n",
        "\n",
        "# Evaluate q_k and p_k values for KL :\n",
        "\n",
        "qk=[]\n",
        "pk=[]\n",
        "for key_14 in counts_14M.keys():\n",
        "    if key_14 in counts:\n",
        "        qk.append(counts[key_14])\n",
        "        pk.append(counts_14M[key_14])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "q_k = list(map((lambda x: x / np.sum(qk)), qk))\n",
        "p_k = list(map((lambda x: x / np.sum(pk)), pk))\n",
        "\n",
        "from scipy import stats\n",
        "print(stats.entropy(p_k , q_k))\n",
        "#0.011069468780077724\n",
        "\n",
        "#KL :\n",
        "q_k = np.array(q_k)\n",
        "p_k = np.array(p_k)\n",
        "\n",
        "KL_model = (p_k * np.log(p_k/q_k)).sum()\n",
        "print(\"KL for the two distribution : \" , KL_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_HXdL_WH5OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtUl5dIbH5L8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99xTeBqUH5J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PioHglxXH5G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEzFXa4NH5Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-E9-TsH5CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RApcb6iH4_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY_AEEoeH49i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_dpPzpsH46u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9UcmyynH44f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g34ZwPA6H41w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT93EAojH4zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fTaMJS6H4wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}